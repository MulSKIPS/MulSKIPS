{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression tests for the mulskips suites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some general considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows developers and users to run a batch of regression tests for the mulskips code.\n",
    "In particular the notebook allows you (in order):\n",
    "- to run several run tests starting from selected input file `start.dat`, each test will run in a dedicated folder containing the mulskips output files;\n",
    "- compare some output \\*.xyz files and the global log.txt;\n",
    "- make a summary of successfull/failed tests, that are green/red marked, respectively.\n",
    "\n",
    "Mulskips is a Kinetic Monte Carlo (KMC) code which aims to simulate the kinetic evolution of an atomistic system based on a-priori defined event frequencies. The  stochastic evolution is driven by a sequence of random numbers generated by well-tested Fortran routines. Random numbers generated by the latter can depend on the machine/compiler.\n",
    "Regression tests in the present notebooks are based on mulskips runs driven by a stored sequence of random numbers.\n",
    "To activate this modality you have to set a \"T\" al line `31` of the `start.dat` input file, which means \"KMC run in test modality\".\n",
    "To check that the code development work did not destroy old functionalities, current output files obtained with the following runs are compared with reference output files.\n",
    "In particular we compare some output files for each test, that are:\n",
    "- the inital KMC input structure `I00000000.xyz` at KMC time = 0 of undercoordinated atoms;\n",
    "- the final KMC structure `I00000001.xyz` of undercoordinated atoms;\n",
    "- the global log file `log.txt`.\n",
    "\n",
    "After the development of some mulskips routine, before commit and push all changes in the github repository, each mulskips developer is supposed to check that old functionality are not broken. This is accomplished with the run of the present regression tests with success.\n",
    "\n",
    "To introduce a new test you need to load in the `input-and-references-files` folder:\n",
    "- a `start.dat` file which corresponds to a mulskips run that touches the modified/developed routines. Mulskips has to run in the test modality, that is you have to set a \"T\" al line `31` of the `start.dat` input file;\n",
    "- its corresponding output reference files;\n",
    "- add the `testname` in the list `tests` below.\n",
    "\n",
    "We associate to each test a name. Input `start.dat` and output \\*.xyz reference files carry such test name.\n",
    "For example, if we are dealing with the test run \"pippo\", then the input file name is `start-pippo.dat`, and output references files are named `I00000000-pippo.xyz` and `I00000001-pippo.xyz`. These files has to be load in the `input-and-references-files` folder During the regression tests a folder `pippo-test` is generated. There we run mulskips with the input `start-pippo.dat` files (renamed as `start.dat`). From this folder we take the current output files and compare them with the reference files. If files are identical, the test is green, and it passed with success. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run regression tests, the user is supposed to set only the variables below of this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full path of the compiled mulskips executable:\n",
    "mulskipsexecutable = '/root/CNR-IMM/mulskips-dev/mulskips-source-walls-CVD/mulskips.e | tee log.txt;'\n",
    "#mulskipsexecutable = '/root/CNR-IMM/mulskips-dev/mulskips-source-walls-CVD/mulskips.e | tee log.txt;'\n",
    "\n",
    "# Directory with all input `start.dat` and reference files.\n",
    "inputrefdir = '/root/CNR-IMM/mulskips-dev/regression-tests-CVD/input-and-references-files/'\n",
    "\n",
    "# List of test names:\n",
    "tests = ['finfet','walls','cube','cube-zigzag','sphere','surface','inverted-pyramid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we run mulskips for all `testname` in `tests` doing the following steps:\n",
    "1. Make a directory `testname`-`test`;\n",
    "2. copy the associated `start-testname.dat` file in `testname`-`test`;\n",
    "3. change from the current working directoty to the `testname`-`test` one;\n",
    "4. run mulskips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /mnt/c/Users/tanoc/OneDrive - University of Pisa/CNR-IMM/mulskips-dev/regression-tests\n"
     ]
    }
   ],
   "source": [
    "# import the os module\n",
    "import os,shutil,subprocess,sys\n",
    "\n",
    "# detect the current working directory and print it\n",
    "cwd = os.getcwd()\n",
    "print (\"The current working directory is %s\" % cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test: finfet\n",
      "\n",
      "Created directory: finfet-test\n",
      "Directory changed to: finfet-test\n",
      "b' IDUM    -9117116\\n'\n",
      "b' numParticelle=      500000 Levels =          20 , SizeTree =     1048575\\n'\n",
      "b' ATTENTION!!! You are running mulskips in test modality that is random numbers are not so random!!\\n'\n",
      "b'      564640           0        2240\\n'\n",
      "b' I00000000\\n'\n",
      "b' NumAtWrong:          120\\n'\n",
      "b'           0\\n'\n",
      "b' I00000001\\n'\n",
      "b' NumAtWrong:          740\\n'\n",
      "b'           0\\n'\n",
      "b' Iter     5000000   616409241072.13831              171         153         849\\n'\n",
      "b' NatNvoidNad      550829           0        4276\\n'\n",
      "b' I00000001\\n'\n",
      "b' NumAtWrong:          739\\n'\n",
      "b'           0\\n'\n",
      "Directory changed to: /mnt/c/Users/tanoc/OneDrive - University of Pisa/CNR-IMM/mulskips-dev/regression-tests\n",
      "\n",
      "Processing test: walls\n",
      "\n",
      "Created directory: walls-test\n",
      "Directory changed to: walls-test\n",
      "b' IDUM    -9117116\\n'\n",
      "b' numParticelle=      500000 Levels =          20 , SizeTree =     1048575\\n'\n",
      "b' ATTENTION!!! You are running mulskips in test modality that is random numbers are not so random!!\\n'\n",
      "b'      374400           0        6400\\n'\n",
      "b' I00000000\\n'\n",
      "b' NumAtWrong:            0\\n'\n",
      "b'           0\\n'\n",
      "b' I00000001\\n'\n",
      "b' NumAtWrong:         1357\\n'\n",
      "b'           0\\n'\n",
      "b' Iter    25000000   1283939858648.3420              447         399         411\\n'\n",
      "b' NatNvoidNad      421953           0       10155\\n'\n",
      "b' I00000001\\n'\n",
      "b' NumAtWrong:         1357\\n'\n",
      "b'           0\\n'\n",
      "Directory changed to: /mnt/c/Users/tanoc/OneDrive - University of Pisa/CNR-IMM/mulskips-dev/regression-tests\n",
      "\n",
      "Processing test: cube\n",
      "\n",
      "Created directory: cube-test\n",
      "Directory changed to: cube-test\n",
      "b' IDUM    -9117116\\n'\n",
      "b' numParticelle=      500000 Levels =          20 , SizeTree =     1048575\\n'\n",
      "b' ATTENTION!!! You are running mulskips in test modality that is random numbers are not so random!!\\n'\n",
      "b'         420         541\\n'\n",
      "b'         180         301\\n'\n",
      "b'        6859           0        2398\\n'\n",
      "b' I00000000\\n'\n",
      "b' NumAtWrong:            0\\n'\n",
      "b'           0\\n'\n"
     ]
    }
   ],
   "source": [
    "for test in tests:\n",
    "    print('Processing test: {}'.format(test))\n",
    "    print('')\n",
    "\n",
    "    # define the name of the directory to be created\n",
    "    testdir = test+'-test'\n",
    "\n",
    "    filenamesrc = inputrefdir+'/start-'+test+'.dat'\n",
    "    filedest = 'start.dat'\n",
    "    \n",
    "    try:\n",
    "        # remove the testdir directory if it already exist\n",
    "        shutil.rmtree(testdir)\n",
    "    except OSError as e:\n",
    "        print(\"Error: %s : %s\" % (testdir, e.strerror))\n",
    "\n",
    "    try:\n",
    "        # create the testdir directory\n",
    "        os.mkdir(testdir)\n",
    "        print('Created directory: {}'.format(testdir))\n",
    "    except OSError:\n",
    "        print('Can not create the Directory: {}'.format(testdir)) \n",
    "\n",
    "    try:\n",
    "        # Change from current working Directory to testdir    \n",
    "        os.chdir(testdir)\n",
    "        print('Directory changed to: {}'.format(testdir))\n",
    "    except OSError:\n",
    "        print(\"Can't change the Current Working Directory\") \n",
    "\n",
    "    shutil.copy(filenamesrc, filedest)\n",
    "\n",
    "    # execute the mulskips.e program with the input file start.dat\n",
    "    make_process = subprocess.Popen(mulskipsexecutable, shell=True, stdout=subprocess.PIPE)\n",
    "    while True:\n",
    "        line = make_process.stdout.readline()\n",
    "        if not line:break\n",
    "        print(line) #output to console in time\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    try:\n",
    "        # Change from current working Directory to testdir    \n",
    "        os.chdir(cwd)\n",
    "        print('Directory changed to: {}'.format(cwd))\n",
    "    except OSError:\n",
    "        print(\"Can't change the Current Working Directory\") \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of current and reference runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following we compare current and reference files. We compare line by line, entry by entry. The comparison stops at the first nonequal entry, and print the line,lineplace and the current and reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(user_input):\n",
    "    vtype = 'notfound'\n",
    "    try:\n",
    "        val = int(user_input)\n",
    "#        print(\"Input is an integer number. Number = \", val)\n",
    "        vtype = 'int'\n",
    "    except ValueError:\n",
    "        try:\n",
    "            val = float(user_input)\n",
    "#            print(\"Input is a float  number. Number = \", val)\n",
    "            vtype = 'float'\n",
    "        except ValueError:\n",
    "#            print(\"No.. input is not a number. It's a string\")\n",
    "            vtype = 'str'\n",
    "    return vtype\n",
    "\n",
    "def reset_value(user_value):\n",
    "    vtype = get_type(user_value)\n",
    "    if vtype == 'int':\n",
    "        new_value = int(user_value)\n",
    "    elif vtype == 'float':\n",
    "        new_value = float(user_value)\n",
    "    elif vtype == 'str':\n",
    "        new_value = str(user_value)\n",
    "    else:\n",
    "        new_value = 'bah'\n",
    "        print('type not found for {}, with type {}'.format(user_value,type(user_value)))\n",
    "    return new_value\n",
    "\n",
    "def print_error(cvalue,rvalue,ind,li):\n",
    "    cv = get_type(cvalue)\n",
    "    rv = get_type(rvalue)\n",
    "    print('Current and Reference values are different: line: {}; position {}.'.format(ind+1,li+1))\n",
    "    print('Current value {}: {}'.format(cvalue,cv))\n",
    "    print('Reference value {}: {}'.format(rvalue,rv))\n",
    "    return    \n",
    "\n",
    "def compare_values(cvalue_input,rvalue_input,tol,ind,li):\n",
    "\n",
    "    cv = get_type(cvalue_input)\n",
    "    rv = get_type(rvalue_input)\n",
    "    cvalue = reset_value(cvalue_input)\n",
    "    rvalue = reset_value(rvalue_input)\n",
    "\n",
    "    if cv != rv:\n",
    "        print('Current and Reference value types are different')\n",
    "        print_error(cvalue,rvalue,ind,li)\n",
    "        teststatus = False\n",
    "    elif cv == rv:\n",
    "        teststatus = True\n",
    "\n",
    "    if teststatus:\n",
    "        if cv == 'str':\n",
    "            if cvalue != rvalue:\n",
    "                print_error(cvalue,rvalue,ind,li)              \n",
    "                teststatus = False\n",
    "            elif cvalue == rvalue:\n",
    "                teststatus = True\n",
    "        elif cv == 'int':\n",
    "            if cvalue != rvalue:\n",
    "                print_error(cvalue,rvalue,ind,li)              \n",
    "                teststatus = False\n",
    "            elif cvalue == rvalue:\n",
    "                teststatus = True\n",
    "        elif cv == 'float':\n",
    "            diff = abs(cvalue-rvalue)\n",
    "            if diff > tol:\n",
    "                print('Current and Reference float values differs for: {}'.format(diff))\n",
    "                print('The tollerance has been set to: {}'.format(tol))\n",
    "                print_error(cvalue,rvalue,ind,li)              \n",
    "                teststatus = False\n",
    "            else:\n",
    "                teststatus = True\n",
    "        else:\n",
    "            print('status not present in the type case list. Type: {}'.format(cv))\n",
    "            print_error(cvalue,rvalue,ind,li)\n",
    "            teststatus = False\n",
    "    return teststatus\n",
    "\n",
    "def compare_files(currfile,reffile,tol):\n",
    "    teststatus = False\n",
    "    \n",
    "    with open (currfile) as cf, open (reffile) as rf:\n",
    "        ccontent = cf.read().splitlines()\n",
    "        rcontent = rf.read().splitlines()\n",
    "\n",
    "        # Compare the lenght of current and reference files. \n",
    "        if len(ccontent) != len(rcontent):\n",
    "            print('Current and Reference files have different lenghts:')\n",
    "            print('Lenght of the current file: {}'.format(len(ccontent)))\n",
    "            print('Lenght of the reference file: {}'.format(len(rcontent)))\n",
    "            teststatus = False\n",
    "        elif len(ccontent) == len(rcontent):\n",
    "            teststatus = True\n",
    "\n",
    "        if teststatus:\n",
    "            for ind in range(len(ccontent)):\n",
    "                cline = ccontent[ind]\n",
    "                rline = rcontent[ind]\n",
    "                cs = cline.split()\n",
    "                rs = rline.split()\n",
    "                    # Compare the lenght of current and reference files. \n",
    "                if len(cs) != len(rs):\n",
    "                    print('Current and Reference lines have different lenghts:')\n",
    "                    print('Lenght of the current line {}: {}'.format(ind,len(cs)))\n",
    "                    print('Lenght of the reference line {}: {}'.format(ind,len(rs)))\n",
    "                    teststatus = False\n",
    "                if teststatus:\n",
    "                    for li in range(len(cs)):\n",
    "                        if teststatus:\n",
    "                            cvalue = cs[li]\n",
    "                            rvalue = rs[li]\n",
    "                            teststatus = compare_values(cvalue,rvalue,tol,ind,li)\n",
    "    return teststatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {}\n",
    "for test in tests:\n",
    "    testdir = test+'-test'\n",
    "    xyzfile0 = 'I00000000' # Input file a KMC time = 0\n",
    "    xyzfile1 = 'I00000001' # Final file at the end of the KMC run\n",
    "    tol = 1.0E-10\n",
    "    teststatus = False\n",
    "    \n",
    "    currfilexyz0 = testdir+'/'+xyzfile0+'.xyz'\n",
    "    reffilexyz0 = inputrefdir+'/'+xyzfile0+'-'+test+'.xyz'\n",
    "    xyz0_teststatus = compare_files(currfilexyz0,reffilexyz0,tol)\n",
    "    print('Status xyz0 test for {}: {}'.format(test,xyz0_teststatus))\n",
    "\n",
    "    currfilexyz1 = testdir+'/'+xyzfile1+'.xyz'\n",
    "    reffilexyz1 = inputrefdir+'/'+xyzfile1+'-'+test+'.xyz'\n",
    "    xyz1_teststatus = compare_files(currfilexyz1,reffilexyz1,tol)\n",
    "    print('Status xyz1 test for {}: {}'.format(test,xyz1_teststatus))\n",
    "\n",
    "    currlog = testdir+'/'+'log.txt'\n",
    "    reflog = inputrefdir+'/'+'log-'+test+'.txt'\n",
    "    log_teststatus = compare_files(currlog,reflog,tol)\n",
    "    print('Status log test for {}: {}'.format(test,log_teststatus))\n",
    "    print('')\n",
    "    \n",
    "    test_results[test] = {'xyz0file': xyz0_teststatus, 'xyz1file': xyz1_teststatus, 'log': log_teststatus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression test report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we report results for all regression tests. A green test means that the test passed with success, and current and reference files are identical. Red tests mean that the test failed, and the developer is supposed to check/identify/resolve all bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(test):\n",
    "    color = 'green'\n",
    "    if test['xyz0file'] and test['xyz1file'] and test['log']:\n",
    "        color = 'green'\n",
    "    else:\n",
    "        color = 'red'\n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from math import sqrt\n",
    "from termcolor import colored\n",
    "\n",
    "results = [(colored(key, color=get_color(test_results[key])), colored(test_results[key]['xyz0file'], color=get_color(test_results[key])), colored(test_results[key]['xyz1file'], color=get_color(test_results[key])), colored(test_results[key]['log'], color=get_color(test_results[key]))) for key in test_results]\n",
    "print(tabulate(results, headers=[\"Test name\", \"initial xyz file\", \"final xyz file\", \"log file\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
